---
title: 'Emergency Fund Modeling with NFCS Data: Financial Literacy Score'
author: "Donnie Minnick"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
---

```{r, message = FALSE}
library("dplyr")
library("ggplot2")
library("knitr")
library("tidyr")

source("../R/get_fl_score.R")

load("../data/nfcs_raw_data.Rdata")
```

# Financial Literacy Score

The NFCS survey contains a set of quiz questions that test a respondent's financial literacy.  
Each question has a correct response and they can be used to create a composite financial literacy score.

A score based on these variables provides a quantitative, objective measure of financial literacy.  
It adds explanatory to the emergency fund model as people with more financial knowledge are more likely to budget, save, avoid debt and prepare for emergencies.

# Survey Questions

Correct responses below signified by (*).

## Interest Calculation (M6)

Suppose you had $100 in a savings account and the interest rate was 2% per year. After 5 years, 
how much do you think you would have in the account if you left the money to grow?

1. More than $102 (*)
2. Exactly $102
3. Less than $102
98. Don't know
99. Prefer not to say

## Inflation (M7)

Imagine that the interest rate on your savings account was 1% per year and inflation was 2% per year. 
After 1 year, how much would you be able to buy with the money in this account?

1. More than today
2. Exactly the same
3. Less than today (*)
98. Don't know
99. Prefer not to say

## Bond Prices Versus Interest Rates (M8)

If interest rates rise, what will typically happen to bond prices?

1. They will rise
2. They will fall (*)
3. They will stay the same
4. There is no relationship between bond prices and the interes
98. Don't know
99. Prefer not to say

## Compound Interest (M31)

Suppose you owe $1,000 on a loan and the interest rate you are charged is 20% per year compounded annually. 
If you didn't pay anything off, at this interest rate, how many years would it take for the amount you owe to double?

1. Less than 2 years
2. At least 2 years but less than 5 years (*)
3. At least 5 years but less than 10 years
4. At least 10 years
98. Don't know
99. Prefer not to say

## Probability (M50)

Which of the following indicates the highest probability of getting a particular disease?

1. There is a one-in-twenty chance of getting the disease (*)
2. 2% of the population will get the disease
3. 25 out of every 1,000 people will get the disease
98. Don't know
99. Prefer not to say

## Mortgage Terms (M9)

A 15-year mortgage typically requires higher monthly payments than a 30-year mortgage, but the 
total interest paid over the life of the loan will be less.

1. True (*)
2. False
98. Don't know
99. Prefer not to say

## Risk Diversification (M10)

Buying a single company's stock usually provides a safer return than a stock mutual fund.

1. True
2. False (*)
98. Don't know
99. Prefer not to say

# Prevalence of Non-Responses

The following table provides a clear picture of how much 'missingness' - non-responses via 
"Don't know" (98) and "Prefer not to say" (99) - exists for each question.  

```{r}
summary_by_question <- nfcs_raw_data %>%
  select(M6, M7, M8, M31, M50, M9, M10) %>%
  pivot_longer(cols = everything(), 
               names_to = "question", 
               values_to = "response") %>%
  mutate(type = case_when(response %in% c(98, 99) ~ "non-response",
                          TRUE ~ "valid")) %>%
  group_by(question, 
           type) %>%
  summarise(count = n(), 
            .groups = "drop") %>%
  group_by(question) %>%
  mutate(total = sum(count),
         percent = round(100 * count / total, 1)) %>%
  pivot_wider(names_from = type,
              values_from = c(count, percent),
              names_glue = "{type}_{.value}",
              values_fill = 0) %>%
  arrange(question)

kable(summary_by_question,
      col.names = c("Question", "Total", "Non-Response Count", "Valid Count", "Non-Response %", "Valid %"),
      caption = "Response Summary by Question",
      format.args = list(big.mark = ","),
      align = c("l", "r", "r", "r", "r", "r"))
```

Two variables, M8 and M10, have a very high non-response, 40.4% and 45.3% respectively; there is a risk 
of biased results if non-responses are included without adjustment.

M7, M31 and M50 have a moderate non-response in the range of 23.1-33.4%, which is potentially tolerable with sensitivity checks.

M6 and M9 have a reasonable retention of data, with non-responses of 20.5% and 15.2%.

M6 has the lowest non-response at 15.2%.

# Proposed Strategy

To deal with this 'missingness', I propose to count "Don't know" (98) responses as incorrect, since it's 
clear "Don't Know" reflects a lack of financial literacy; otherwise, the respondent would be provided a 
different answer.  It is reasonable to conclude it as an incorrect response.

Exclude "Prefer not to say" (99) responses from scoring, since "Prefer not to answer" may reflect a 
non-engagement or privacy concern, and not necessarily knowledge.  Given that these responses are a 
small subset, excluding them avoids misclassifying intent and doesn't hurt power.

I will implement and evaluate percent metrics based on both the number of correct responses, excluding 99, 
and based on the total number of survey questions, i.e. the seven quiz questions.  This approach potentially 
avoids a situation where a respondent receives a high percent score as a result of 99 responses.  Calculating 
both metrics provides the option to evaluate each and decide which is more appropriate during analysis.

# Impacts on a Financial Literacy Score

The proposed strategy will result in more people receiving lower scores.  Since "Don't know" (98) responses 
will be treated as incorrect, respondents with even partial uncertainty will get lower scores.

This shifts the distribution left (lower average score), especially on questions with high "Don't know (98) rates like M10, M8, M50.

# get_fl_score Function

I implemented a `get_fl_score` function to create a composite score using the survey responses.

The function returns a list with four values:

* `raw_score` returns number of correct responses; it excludes both "Don't know" (98) and "Prefer not to say" (98),
* `percent_score` returns percent of correct responses, excluding answers marked as "Prefer not to say" (99),
* `normalized_score` returns percent of correct responses using number of survey questions as the denominator, and
* `questions_answered` returns the number of answered questions, including "Don't know" (98).

The `normalized_score` corrects for situations in which a survey has a prevalence of "Prefer not to say" (99) responses.

Here is an example that illustrates the problem with a single survey response.  In this example, a respondent 
responds with "Prefer not to say" (99) for six of seven questions.

```{r}
get_fl_score(1, 99, 99, 99, 99, 99, 99)
```

The `raw_score` is 1 and the `percent_score`, which excludes "Don't know" (98) and "Prefer not to say" (99) 
responses, returns a perfect score, i.e. 1 correct response divided by 1 respond provided.  `normalized_score` 
reflects the percent based on attempted responses, excluding "Don't know" (98) and "Prefer not to say" (99).

# get_fl_score Test

```{r}
fl_responses <- nfcs_raw_data %>%
  select(M6, M7, M8, M31, M50, M9, M10) %>%
  rowwise() %>%
  mutate(fl_score_raw = as.integer(get_fl_score(M6, M7, M8, M31, M50, M9, M10)$raw_score),
         fl_score_pct = as.numeric(get_fl_score(M6, M7, M8, M31, M50, M9, M10)$percent_score),
         fl_score_nml = as.numeric(get_fl_score(M6, M7, M8, M31, M50, M9, M10)$normalized_score),
         fl_questions_answered = as.numeric(get_fl_score(M6, M7, M8, M31, M50, M9, M10)$questions_answered))

kable(head(fl_responses, 15),
      col.names = c("M6", "M7", "M8", "M31", "M50", "M9", "M10", "Raw Score", "% Score", "Normalized Score", "Questions Answered"),
      caption = "Literacy Score Test Example",
      format.args = list(big.mark = ","),
      align = c("r", "r", "r", "r", "r", "r", "r", "r", "r", "r", "r"))
```

To get a better sense of the distribution of scores by type of scope, I will group respondents by score type 
to get a sense of how misleading the percent score might be.

```{r}
fl_summary <- fl_responses %>%
  group_by(fl_score_raw, fl_score_pct, fl_score_nml) %>%
  summarise(respondents = n())

kable(fl_summary,
      col.names = c("Raw Score", "% Score", "Normalized Score", "Respondents"),
      caption = "Summary of Respondents by Grouped Scores",
      format.args = list(big.mark = ","),
      align = c("r", "r", "r", "r"))
```

Most respondents are answering at least some of the questions.  Only 45 respondents had all "Prefer not to say" (99) 
responses, so most respondents are engaging with the survey on some level.

Percent scores tend to cluster at whole-number raw scores with matching expected percentage scores, e.g. 0/7 = 0%, 
1/7 ≈ 14.3%, etc. This suggests most people completed all 7 questions, or at least a consistent subset.

The cases where percent scores deviate from the typical 14.3% steps, e.g. 1 correct out of 3 = 33.3%, are relatively 
rare. This implies that skipping or “Prefer not to answer” (99) responses did not dramatically skew the data for most people.

The largest groups of respondents scored between 2 and 5 correct answers, with fewer at the extremes. This is a 
typical bell-shaped distribution, which is expected in general population-level financial literacy assessments.

The consistent pattern between raw, percent, and normalized scores supports that this scoring logic is working 
correctly and the data is clean and interpretable.

In summary, this data confirms that the strategy for handling non-responses is not introducing distortion, and 
it provides a nuanced view of the financial literacy levels in the sample.

Here's the distribution of raw and percent scores in a plot.

```{r}
fl_summary_grouped <- fl_summary %>%
  filter(!is.na(fl_score_raw)) %>%
  mutate(literacy_level = case_when(fl_score_raw <= 2 ~ "Low",
                                    fl_score_raw <= 5 ~ "Medium",
                                    fl_score_raw <= 7 ~ "High"),
         literacy_level = factor(literacy_level, levels = c("Low", "Medium", "High")))

ggplot(fl_summary_grouped, aes(x = factor(fl_score_raw), y = respondents, fill = literacy_level)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = respondents), vjust = -0.5, size = 3.0) +
  scale_fill_manual(values = c("Low" = "#D73027", "Medium" = "#FDAE61", "High" = "#1A9850"),
                    name = "Literacy Level") +
  labs(title = "Distribution of Financial Literacy Scores",
       x = "Financial Literacy Score (Raw)",
       y = "Number of Respondents") +
  theme(plot.title = element_text(size = 14, face = "bold"),
        axis.title = element_text(size = 12),
        legend.position = "top")

```

This distribution reveals that the financial literacy score follows a roughly normal pattern, peaking around 
scores of 3 and 4, which suggests a moderate overall level of financial literacy among respondents. The number 
of individuals scoring at the extremes (0 or 7) is relatively low, while many fall into the middle range.
